{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code are based on:<br>\n",
        "https://www.kaggle.com/code/chaos2629/transformer-model-training <br>\n",
        "and <br>\n",
        "https://www.kaggle.com/code/charanreddysunkara/gislr-tf-data-processing-transformer-training"
      ],
      "metadata": {
        "id": "ouZHt5o52vf5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de4Hht1Krdg4",
        "outputId": "b4bd6096-9e74-46b6-a9ce-becdbee0fe38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas pyarrow\n",
        "!pip install -q mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7beuGRzYri-M",
        "outputId": "08e65636-bcac-43ae-90a3-7962e2b95b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Folder Directry\n",
        "main_dir = '/content/drive/MyDrive/Colab Notebooks/Data/asl-signs/'"
      ],
      "metadata": {
        "id": "8Kx4Az8srlcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "import json\n",
        "# Constants (adjust these according to your data)\n",
        "INPUT_SIZE = 64\n",
        "N_COLS = 100  # Adjust based on your landmark indices\n",
        "N_DIMS = 3    # Typically x, y, z coordinates\n",
        "N_ROWS = 543"
      ],
      "metadata": {
        "id": "8xeIwXaOrqVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load metadata\n",
        "metadata_sub_dir = 'train.csv'\n",
        "metadata_full_file_path = os.path.join(main_dir, metadata_sub_dir)\n",
        "df_metadata = pd.read_csv(metadata_full_file_path)\n",
        "\n",
        "# Load sign to index mapping\n",
        "signmap_sub_dir = 'sign_to_prediction_index_map.json'\n",
        "signmap_full_file_path = os.path.join(main_dir, signmap_sub_dir)\n",
        "with open(signmap_full_file_path, 'r') as file:\n",
        "    sign_to_index = json.load(file)\n",
        "df_metadata['sign_index'] = df_metadata['sign'].map(sign_to_index)"
      ],
      "metadata": {
        "id": "51E7Os2trrK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_TYPES = ['left_hand', 'pose', 'right_hand']\n",
        "START_IDX = 468\n",
        "LIPS_IDXS0 = np.array([\n",
        "        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
        "        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
        "        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
        "        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
        "    ])\n",
        "# Landmark indices in original data\n",
        "LEFT_HAND_IDXS0 = np.arange(468,489)\n",
        "RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
        "LEFT_POSE_IDXS0 = np.array([502, 504, 506, 508, 510])\n",
        "RIGHT_POSE_IDXS0 = np.array([503, 505, 507, 509, 511])\n",
        "LANDMARK_IDXS_LEFT_DOMINANT0 = np.concatenate((LIPS_IDXS0, LEFT_HAND_IDXS0, LEFT_POSE_IDXS0))\n",
        "LANDMARK_IDXS_RIGHT_DOMINANT0 = np.concatenate((LIPS_IDXS0, RIGHT_HAND_IDXS0, RIGHT_POSE_IDXS0))\n",
        "HAND_IDXS0 = np.concatenate((LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0), axis=0)\n",
        "N_COLS = LANDMARK_IDXS_LEFT_DOMINANT0.size\n",
        "# Landmark indices in processed data\n",
        "LIPS_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LIPS_IDXS0)).squeeze()\n",
        "LEFT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LEFT_HAND_IDXS0)).squeeze()\n",
        "RIGHT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, RIGHT_HAND_IDXS0)).squeeze()\n",
        "HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, HAND_IDXS0)).squeeze()\n",
        "POSE_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LEFT_POSE_IDXS0)).squeeze()\n",
        "\n",
        "print(f'# HAND_IDXS: {len(HAND_IDXS)}, N_COLS: {N_COLS}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEBasvWVt0ur",
        "outputId": "103d5b63-2eb6-437a-83fc-8e2d21d9467b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# HAND_IDXS: 21, N_COLS: 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LIPS_START = 0\n",
        "LEFT_HAND_START = LIPS_IDXS.size\n",
        "RIGHT_HAND_START = LEFT_HAND_START + LEFT_HAND_IDXS.size\n",
        "POSE_START = RIGHT_HAND_START + RIGHT_HAND_IDXS.size\n",
        "\n",
        "print(f'LIPS_START: {LIPS_START}, LEFT_HAND_START: {LEFT_HAND_START}, RIGHT_HAND_START: {RIGHT_HAND_START}, POSE_START: {POSE_START}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsO9MHV5t46o",
        "outputId": "3f3d45a6-29bd-4736-aa26-83cc635b00aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIPS_START: 0, LEFT_HAND_START: 40, RIGHT_HAND_START: 61, POSE_START: 61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
        "def load_and_preprocess_data(file_path, preprocess_layer):\n",
        "    # Load data\n",
        "    data_columns = ['x', 'y', 'z']\n",
        "    data = pd.read_parquet(file_path, columns=data_columns)\n",
        "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
        "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
        "    # Apply preprocessing using the PreprocessLayer\n",
        "    processed_data = preprocess_layer(data.astype(np.float32))\n",
        "\n",
        "    return processed_data\n",
        "\n"
      ],
      "metadata": {
        "id": "_oXB7d91r4I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If True, processing data from scratch\n",
        "# If False, loads preprocessed data\n",
        "PREPROCESS_DATA = False\n",
        "TRAIN_MODEL = True\n",
        "# True: use 10% of participants as validation set\n",
        "# False: use all data for training -> gives better LB result\n",
        "USE_VAL = False\n",
        "\n",
        "N_ROWS = 543\n",
        "N_DIMS = 3\n",
        "DIM_NAMES = ['x', 'y', 'z']\n",
        "SEED = 42\n",
        "NUM_CLASSES = 250\n",
        "IS_INTERACTIVE = True\n",
        "VERBOSE = 1 if IS_INTERACTIVE else 2\n",
        "\n",
        "INPUT_SIZE = 64\n",
        "\n",
        "BATCH_ALL_SIGNS_N = 4\n",
        "BATCH_SIZE = 256\n",
        "N_EPOCHS = 100\n",
        "LR_MAX = 1e-3\n",
        "N_WARMUP_EPOCHS = 0\n",
        "WD_RATIO = 0.05\n",
        "MASK_VAL = 4237"
      ],
      "metadata": {
        "id": "6zpdiLgjtn4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Tensorflow layer to process data in TFLite\n",
        "    Data needs to be processed in the model itself, so we can not use Python\n",
        "\"\"\"\n",
        "class PreprocessLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(PreprocessLayer, self).__init__()\n",
        "        normalisation_correction = tf.constant([\n",
        "                    # Add 0.50 to left hand (original right hand) and substract 0.50 of right hand (original left hand)\n",
        "                    [0] * len(LIPS_IDXS) + [0.50] * len(LEFT_HAND_IDXS) + [0.50] * len(POSE_IDXS),\n",
        "                    # Y coordinates stay intact\n",
        "                    [0] * len(LANDMARK_IDXS_LEFT_DOMINANT0),\n",
        "                    # Z coordinates stay intact\n",
        "                    [0] * len(LANDMARK_IDXS_LEFT_DOMINANT0),\n",
        "                ],\n",
        "                dtype=tf.float32,\n",
        "            )\n",
        "        self.normalisation_correction = tf.transpose(normalisation_correction, [1,0])\n",
        "\n",
        "    def pad_edge(self, t, repeats, side):\n",
        "        if side == 'LEFT':\n",
        "            return tf.concat((tf.repeat(t[:1], repeats=repeats, axis=0), t), axis=0)\n",
        "        elif side == 'RIGHT':\n",
        "            return tf.concat((t, tf.repeat(t[-1:], repeats=repeats, axis=0)), axis=0)\n",
        "\n",
        "    @tf.function(\n",
        "        input_signature=(tf.TensorSpec(shape=[None,N_ROWS,N_DIMS], dtype=tf.float32),),\n",
        "    )\n",
        "    def call(self, data0):\n",
        "        # Number of Frames in Video\n",
        "        N_FRAMES0 = tf.shape(data0)[0]\n",
        "\n",
        "        # Find dominant hand by comparing summed absolute coordinates\n",
        "        left_hand_sum = tf.math.reduce_sum(tf.where(tf.math.is_nan(tf.gather(data0, LEFT_HAND_IDXS0, axis=1)), 0, 1))\n",
        "        right_hand_sum = tf.math.reduce_sum(tf.where(tf.math.is_nan(tf.gather(data0, RIGHT_HAND_IDXS0, axis=1)), 0, 1))\n",
        "        left_dominant = left_hand_sum >= right_hand_sum\n",
        "\n",
        "        # Count non NaN Hand values in each frame for the dominant hand\n",
        "        if left_dominant:\n",
        "            frames_hands_non_nan_sum = tf.math.reduce_sum(\n",
        "                    tf.where(tf.math.is_nan(tf.gather(data0, LEFT_HAND_IDXS0, axis=1)), 0, 1),\n",
        "                    axis=[1, 2],\n",
        "                )\n",
        "        else:\n",
        "            frames_hands_non_nan_sum = tf.math.reduce_sum(\n",
        "                    tf.where(tf.math.is_nan(tf.gather(data0, RIGHT_HAND_IDXS0, axis=1)), 0, 1),\n",
        "                    axis=[1, 2],\n",
        "                )\n",
        "\n",
        "        # Find frames indices with coordinates of dominant hand\n",
        "        non_empty_frames_idxs = tf.where(frames_hands_non_nan_sum > 0)\n",
        "        non_empty_frames_idxs = tf.squeeze(non_empty_frames_idxs, axis=1)\n",
        "        # Filter frames\n",
        "        data = tf.gather(data0, non_empty_frames_idxs, axis=0)\n",
        "\n",
        "        # Cast Indices in float32 to be compatible with Tensorflow Lite\n",
        "        non_empty_frames_idxs = tf.cast(non_empty_frames_idxs, tf.float32)\n",
        "        # Normalize to start with 0\n",
        "        non_empty_frames_idxs -= tf.reduce_min(non_empty_frames_idxs)\n",
        "\n",
        "        # Number of Frames in Filtered Video\n",
        "        N_FRAMES = tf.shape(data)[0]\n",
        "\n",
        "        # Gather Relevant Landmark Columns\n",
        "        if left_dominant:\n",
        "            data = tf.gather(data, LANDMARK_IDXS_LEFT_DOMINANT0, axis=1)\n",
        "        else:\n",
        "            data = tf.gather(data, LANDMARK_IDXS_RIGHT_DOMINANT0, axis=1)\n",
        "            data = (\n",
        "                    self.normalisation_correction + (\n",
        "                        (data - self.normalisation_correction) * tf.where(self.normalisation_correction != 0, -1.0, 1.0))\n",
        "                )\n",
        "\n",
        "        # Video fits in INPUT_SIZE\n",
        "        if N_FRAMES < INPUT_SIZE:\n",
        "            # Pad With -1 to indicate padding\n",
        "            non_empty_frames_idxs = tf.pad(non_empty_frames_idxs, [[0, INPUT_SIZE-N_FRAMES]], constant_values=-1)\n",
        "            # Pad Data With Zeros\n",
        "            data = tf.pad(data, [[0, INPUT_SIZE-N_FRAMES], [0,0], [0,0]], constant_values=0)\n",
        "            # Fill NaN Values With 0\n",
        "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
        "            return data, non_empty_frames_idxs\n",
        "        # Video needs to be downsampled to INPUT_SIZE\n",
        "        else:\n",
        "            # Repeat\n",
        "            if N_FRAMES < INPUT_SIZE**2:\n",
        "                repeats = tf.math.floordiv(INPUT_SIZE * INPUT_SIZE, N_FRAMES0)\n",
        "                data = tf.repeat(data, repeats=repeats, axis=0)\n",
        "                non_empty_frames_idxs = tf.repeat(non_empty_frames_idxs, repeats=repeats, axis=0)\n",
        "\n",
        "            # Pad To Multiple Of Input Size\n",
        "            pool_size = tf.math.floordiv(len(data), INPUT_SIZE)\n",
        "            if tf.math.mod(len(data), INPUT_SIZE) > 0:\n",
        "                pool_size += 1\n",
        "\n",
        "            if pool_size == 1:\n",
        "                pad_size = (pool_size * INPUT_SIZE) - len(data)\n",
        "            else:\n",
        "                pad_size = (pool_size * INPUT_SIZE) % len(data)\n",
        "\n",
        "            # Pad Start/End with Start/End value\n",
        "            pad_left = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(INPUT_SIZE, 2)\n",
        "            pad_right = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(INPUT_SIZE, 2)\n",
        "            if tf.math.mod(pad_size, 2) > 0:\n",
        "                pad_right += 1\n",
        "\n",
        "            # Pad By Concatenating Left/Right Edge Values\n",
        "            data = self.pad_edge(data, pad_left, 'LEFT')\n",
        "            data = self.pad_edge(data, pad_right, 'RIGHT')\n",
        "\n",
        "            # Pad Non Empty Frame Indices\n",
        "            non_empty_frames_idxs = self.pad_edge(non_empty_frames_idxs, pad_left, 'LEFT')\n",
        "            non_empty_frames_idxs = self.pad_edge(non_empty_frames_idxs, pad_right, 'RIGHT')\n",
        "\n",
        "            # Reshape to Mean Pool\n",
        "            data = tf.reshape(data, [INPUT_SIZE, -1, N_COLS, N_DIMS])\n",
        "            non_empty_frames_idxs = tf.reshape(non_empty_frames_idxs, [INPUT_SIZE, -1])\n",
        "\n",
        "            # Mean Pool\n",
        "            data = tf.experimental.numpy.nanmean(data, axis=1)\n",
        "            non_empty_frames_idxs = tf.experimental.numpy.nanmean(non_empty_frames_idxs, axis=1)\n",
        "\n",
        "            # Fill NaN Values With 0\n",
        "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
        "\n",
        "            return data, non_empty_frames_idxs\n",
        "\n",
        "preprocess_layer = PreprocessLayer()"
      ],
      "metadata": {
        "id": "MZcOTEBstSBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess the entire dataset\n",
        "def preprocess_data(df, main_dir, preprocess_layer):\n",
        "    X = np.zeros([len(df), INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n",
        "    y = np.zeros([len(df)], dtype=np.int32)\n",
        "    NON_EMPTY_FRAME_IDXS = np.full([len(df), INPUT_SIZE], -1, dtype=np.float32)\n",
        "\n",
        "    for row_idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        file_path = os.path.join(main_dir, row['path'])\n",
        "        processed_data, non_empty_frame_idxs = load_and_preprocess_data(file_path, preprocess_layer)\n",
        "        X[row_idx] = processed_data\n",
        "        y[row_idx] = row['sign_index']\n",
        "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
        "    # Save processed data\n",
        "    np.save(os.path.join(main_dir, 'X.npy'), X)\n",
        "    np.save(os.path.join(main_dir, 'y.npy'), y)\n",
        "    np.save(os.path.join(main_dir, 'NON_EMPTY_FRAME_IDXS.npy'), NON_EMPTY_FRAME_IDXS)\n",
        "\n",
        "    # Optional: Train-Validation Split\n",
        "    splitter = GroupShuffleSplit(test_size=0.10, n_splits=2, random_state=42)\n",
        "    train_idxs, val_idxs = next(splitter.split(X, y, groups=df['participant_id']))\n",
        "\n",
        "    # Save Train and Validation Sets\n",
        "    X_train = X[train_idxs]\n",
        "    NON_EMPTY_FRAME_IDXS_TRAIN = NON_EMPTY_FRAME_IDXS[train_idxs]\n",
        "    y_train = y[train_idxs]\n",
        "    np.save(os.path.join(main_dir, 'X_train.npy'), X[train_idxs])\n",
        "    np.save(os.path.join(main_dir, 'y_train.npy'), y[train_idxs])\n",
        "    np.save('NON_EMPTY_FRAME_IDXS_TRAIN.npy', NON_EMPTY_FRAME_IDXS_TRAIN)\n",
        "    X_val = X[val_idxs]\n",
        "    NON_EMPTY_FRAME_IDXS_VAL = NON_EMPTY_FRAME_IDXS[val_idxs]\n",
        "    y_val = y[val_idxs]\n",
        "    np.save(os.path.join(main_dir, 'X_val.npy'), X[val_idxs])\n",
        "    np.save(os.path.join(main_dir, 'y_val.npy'), y[val_idxs])\n",
        "    np.save('NON_EMPTY_FRAME_IDXS_VAL.npy', NON_EMPTY_FRAME_IDXS_VAL)\n",
        "\n",
        "# Run the preprocessing\n",
        "preprocess_data(df_metadata, main_dir, preprocess_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "2BI_RT70r6jf",
        "outputId": "d029f3ee-3933-4d32-bcd0-b66fd5a81764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 31912/94477 [3:58:52<7:48:19,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             result = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2827\u001b[0;31m         return dataset.read(columns=columns, use_threads=use_threads,\n\u001b[0m\u001b[1;32m   2828\u001b[0m                             use_pandas_metadata=use_pandas_metadata)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m         table = self._dataset.to_table(\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_expression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Scanner.to_table\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ad3012c212dd>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Run the preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-ad3012c212dd>\u001b[0m in \u001b[0;36mpreprocess_data\u001b[0;34m(df, main_dir, preprocess_layer)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprocessed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_empty_frame_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sign_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-71ccb6602f8e>\u001b[0m in \u001b[0;36mload_and_preprocess_data\u001b[0;34m(file_path, preprocess_layer)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mn_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mROWS_PER_FRAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mROWS_PER_FRAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_handles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_handles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_handles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_wrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected"
          ]
        }
      ]
    }
  ]
}